{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKVxN2YY0f_G"
      },
      "outputs": [],
      "source": [
        "import math, random\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, utils as vutils\n",
        "from dataclasses import dataclass\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from torchvision.models import inception_v3, Inception_V3_Weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"DEVICE : {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o96Wrd0k0ypo",
        "outputId": "deb9ff3c-3ceb-40f9-c5b2-109ba7cd6b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionSchedule():\n",
        "    def __init__(self,\n",
        "                 T : int = 1000,\n",
        "                 beta_start : float = 1e-4,\n",
        "                 beta_end : float = 2e-2,\n",
        "                 use_elbo_wts : bool = False,\n",
        "                 group_norm_batch_size : int = 8):\n",
        "        self.T = T\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.use_elbo_wts = use_elbo_wts\n",
        "        self.group_norm_batch_size = group_norm_batch_size if group_norm_batch_size is not None else 8\n",
        "\n",
        "        self.betas = torch.linspace(beta_start, beta_end, T, dtype = torch.float32)\n",
        "        self.alphas = 1 - self.betas\n",
        "        self.a_bar = torch.cumprod(self.alphas, dim = 0)\n",
        "        self.sqrt_a_bar = torch.sqrt(self.a_bar)\n",
        "        self.sqrt_one_minus_a_bar = torch.sqrt(1 - self.a_bar)\n",
        "        self.a_bar_prev = torch.cat([torch.tensor([1.0]), self.a_bar[: -1]], dim = 0)\n",
        "        self.post_var = self.betas * ((1.0 - self.a_bar_prev) / (1.0 - self.a_bar)) # beta_tilde\n",
        "\n",
        "    def to(self, device):\n",
        "        for k, v in self.__dict__.items():\n",
        "            if torch.is_tensor(v):\n",
        "                setattr(self, k, v.to(device))\n",
        "        return self"
      ],
      "metadata": {
        "id": "XisIHvIBBL_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sched = DiffusionSchedule().to(device)"
      ],
      "metadata": {
        "id": "_7-ok78WCM7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SineTimeEmbedding(nn.Module):\n",
        "    def __init__(self, dim : int):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.mlp = nn.Sequential(nn.Linear(dim, 2 * dim), nn.SiLU(), nn.Linear(2 * dim, dim))\n",
        "\n",
        "    def forward(self, time_vals : torch.Tensor, base : float = 10000.0):\n",
        "        # time_vals : [B, ] , Contains time step values\n",
        "        half = self.dim // 2\n",
        "        freqs = torch.exp(-1 * (torch.arange(0, half, dtype = torch.float32, device = time_vals.device) / (half)) * math.log(base))\n",
        "        args = time_vals[:, None] * freqs[None, :]\n",
        "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim = -1)\n",
        "        return self.mlp(emb)"
      ],
      "metadata": {
        "id": "dca0h4KkEPO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassEmbedding(nn.Module):\n",
        "    def __init__(self, num_classes : int = 10, dim : int = 128):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(num_classes + 1, dim)\n",
        "        # +1 class for CFG.\n",
        "\n",
        "    def forward(self, y):\n",
        "        # y : [B, ], List of class values\n",
        "        return self.embed(y)"
      ],
      "metadata": {
        "id": "B7fxxSlcG9bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_params = lambda m : sum([p.numel() for p in m.parameters()])"
      ],
      "metadata": {
        "id": "vz5Zf8EhHHP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, cond_dim):\n",
        "        super().__init__()\n",
        "        self.norm_1 = nn.GroupNorm(sched.group_norm_batch_size, in_ch)\n",
        "        self.conv_1 = nn.Conv2d(in_ch, out_ch, kernel_size = 3, padding = 1)\n",
        "        self.norm_2 = nn.GroupNorm(sched.group_norm_batch_size, out_ch)\n",
        "        self.conv_2 = nn.Conv2d(out_ch, out_ch, kernel_size = 3, padding = 1)\n",
        "        self.skip = nn.Conv2d(in_ch, out_ch, kernel_size = 1) if in_ch != out_ch else nn.Identity()\n",
        "        self.cond = nn.Sequential(nn.SiLU(), nn.Linear(cond_dim, 2 * out_ch))\n",
        "\n",
        "    def forward(self, x : torch.tensor, cond_vec : torch.tensor):\n",
        "        h = self.conv_1(F.silu(self.norm_1(x)))\n",
        "        h = self.norm_2(h)\n",
        "        gamma, beta = self.cond(cond_vec).chunk(2, dim = -1)\n",
        "        h = ((1 + gamma[:, :, None, None]) * h) + beta[:, :, None, None]\n",
        "        h = self.conv_2(F.silu(h))\n",
        "        return h + self.skip(x)"
      ],
      "metadata": {
        "id": "fgadKqBuI6wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpSample(nn.Module):\n",
        "    def __init__(self, ch):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(ch, ch, kernel_size = 3, padding = 1)\n",
        "\n",
        "    def forward(self, x : torch.tensor):\n",
        "        return self.conv(F.interpolate(x, scale_factor = 2, mode = \"nearest\"))\n",
        "\n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, ch):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(ch, ch, kernel_size = 3, stride = 2, padding = 1)\n",
        "\n",
        "    def forward(self, x : torch.tensor):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "ONMZe8JZhL0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "    def __init__(self, num_classes : int = 10, in_channels : int = 1, base : int = 32, cond_dim : int = 128):\n",
        "        super().__init__()\n",
        "        self.time_emb = SineTimeEmbedding(cond_dim)\n",
        "        self.class_emb = ClassEmbedding(num_classes, cond_dim)\n",
        "\n",
        "        self.in_conv = nn.Conv2d(in_channels, base, kernel_size = 3, padding = 1)\n",
        "\n",
        "        self.d1 = ConvResBlock(base, base, cond_dim)\n",
        "        self.d2 = ConvResBlock(base, 2 * base, cond_dim)\n",
        "        self.down_1 = DownSample(2 * base)\n",
        "        self.d3 = ConvResBlock(2 * base, 2 * base, cond_dim)\n",
        "        self.d4 = ConvResBlock(2 * base, 4 * base, cond_dim)\n",
        "        self.down_2 = DownSample(4 * base)\n",
        "\n",
        "        self.mid = ConvResBlock(4 * base, 4 * base, cond_dim)\n",
        "\n",
        "        self.u1 = ConvResBlock(4 * base, 4 * base, cond_dim)\n",
        "        self.up_1 = UpSample(4 * base)\n",
        "        self.u2 = ConvResBlock(4 * base + 4 * base, 2 * base, cond_dim)\n",
        "        self.u3 = ConvResBlock(2 * base, 2 * base, cond_dim)\n",
        "        self.up_2 = UpSample(2 * base)\n",
        "        self.u4 = ConvResBlock(2 * base + 2 * base, base, cond_dim)\n",
        "\n",
        "        self.out_norm = nn.GroupNorm(sched.group_norm_batch_size, base)\n",
        "        self.out_conv = nn.Conv2d(base, in_channels, kernel_size = 3, padding = 1)\n",
        "\n",
        "\n",
        "    def forward(self, x : torch.tensor, t : torch.tensor, y : torch.tensor):\n",
        "        # x : [B, c, h, w]\n",
        "        # t : [B, ], y : [B, ]\n",
        "        cond_vec = self.time_emb(t) + self.class_emb(y)\n",
        "        h0 = self.in_conv(x) # [B, base, h, w]\n",
        "        h1 = self.d1(h0, cond_vec) # [B, base, h, w]\n",
        "        h2 = self.d2(h1, cond_vec) # [B, 2 * base, h, w]\n",
        "        h3 = self.down_1(h2) # [B, 2 * base, h / 2, w / 2]\n",
        "        h3 = self.d3(h3, cond_vec) # [B, 2 * base, h / 2, w / 2]\n",
        "        h4 = self.d4(h3, cond_vec) # [B, 4 * base, h / 2, w / 2]\n",
        "        h5 = self.down_2(h4) # [B, 4 * base, h / 4, w / 4]\n",
        "\n",
        "        hm = self.mid(h5, cond_vec) # [B, 4 * base, h / 4, w / 4]\n",
        "\n",
        "        hu = self.u1(hm, cond_vec) # [B, 4 * base, h / 4, w / 4]\n",
        "        hu = self.up_1(hu) # [B, 4 * base, h / 2, w / 2]\n",
        "        hu = self.u2(torch.cat([hu, h4], dim = 1), cond_vec) # [B, 2 * base, h / 2, w / 2]\n",
        "        hu = self.u3(hu, cond_vec) # [B, 2 * base, h / 2, w / 2]\n",
        "        hu = self.up_2(hu) # [B, 2 * base, h, w]\n",
        "        hu = self.u4(torch.cat([hu, h2], dim = 1), cond_vec) # [B, base, h, w]\n",
        "\n",
        "        out_x = self.out_conv(F.silu(self.out_norm(hu)))\n",
        "        return out_x"
      ],
      "metadata": {
        "id": "MLAZ7eUbhtjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def q_sample(x_0 : torch.tensor, t : torch.tensor, noise = None):\n",
        "    # x_0 : [B, c, h, w], t : [B, ]\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x_0)\n",
        "\n",
        "    # q(x_t | x_0) ~ N(sqrt_a_bar[t] * x_0, (1 - a_bar[t]) * I)\n",
        "    return (x_0 * sched.sqrt_a_bar[t].view(-1, 1, 1, 1)) + (noise * sched.sqrt_one_minus_a_bar[t].view(-1, 1, 1, 1)), noise"
      ],
      "metadata": {
        "id": "hisHFnvpislD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_eps(model, x_0, t, y, weighted = False):\n",
        "    x_t, eps = q_sample(x_0, t)\n",
        "    eps_pred = model(x_t, t, y)\n",
        "    mse = pow(eps_pred - eps, 2).mean(dim = (1, 2, 3))\n",
        "    if weighted:\n",
        "        wt = sched.betas[t] / (sched.alphas[t] * (1 - sched.a_bar_prev[t]) * 2.0)\n",
        "        mse *= wt\n",
        "    return mse.mean()"
      ],
      "metadata": {
        "id": "36t7ct-FpYjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist_loader(batch_size = 128, root = \"./data/\"):\n",
        "    tfm = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x : (x * 2.0) - 1.0)\n",
        "    ])\n",
        "\n",
        "    train = datasets.MNIST(root, train = True, transform = tfm, download = True)\n",
        "    test = datasets.MNIST(root, train = False, transform = tfm, download = True)\n",
        "\n",
        "    return (DataLoader(train, batch_size = batch_size, shuffle = True, num_workers = 2, pin_memory = True),\n",
        "            DataLoader(test, batch_size = batch_size, shuffle = False, num_workers = 2, pin_memory = True))"
      ],
      "metadata": {
        "id": "4sWpp9s7HU3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = mnist_loader()"
      ],
      "metadata": {
        "id": "tWvDMhK6HWug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3b288e-972d-4e18-a6d0-c8a6d0f6eef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 57.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.64MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.5MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.86MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EMA:\n",
        "    def __init__(self, model, decay : float = 0.999):\n",
        "        self.model = model\n",
        "        self.decay = decay\n",
        "        self.shadow = [p.detach().clone() for p in model.parameters()] # shadow wts to be used instead during inference.\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update(self):\n",
        "        for i, p in enumerate(self.model.parameters()):\n",
        "            self.shadow[i] = (self.shadow[i] * self.decay) + p.detach() * (1 - self.decay)\n",
        "\n",
        "    def store(self):\n",
        "        self.backup = [p.detach().clone() for p in self.model.parameters()]\n",
        "\n",
        "    def copy_to(self):\n",
        "        for p, s in zip(self.model.parameters(), self.shadow):\n",
        "            p.copy_(s)\n",
        "\n",
        "    def restore(self):\n",
        "        for p, b in zip(self.model.parameters(), self.backup):\n",
        "            p.copy_(b)"
      ],
      "metadata": {
        "id": "huUQrc9JJSGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def sample_grid(model, y, num_imgs = 16, img_shape = (1, 28, 28), steps = None, cfg_scale = 3.0, sigma_choice = \"beta_tilde\", num_classes = 10, device = device):\n",
        "    model.eval()\n",
        "    x = torch.randn([num_imgs, *img_shape], device = device)\n",
        "    y = y.to(device)\n",
        "    steps = steps if steps is not None else sched.T\n",
        "    per_step = max(1, sched.T // steps)\n",
        "\n",
        "    t_seq = torch.arange(sched.T - 1, -1, -per_step, dtype = torch.int64, device = device)\n",
        "\n",
        "    for ti in t_seq:\n",
        "        t = torch.full((num_imgs, ), ti, dtype = torch.int64, device = device)\n",
        "        null_id = num_classes\n",
        "\n",
        "        y_uncond = torch.full_like(y, null_id)\n",
        "        x_in = torch.cat([x, x], dim = 0)\n",
        "        y_in = torch.cat([y_uncond, y], dim = 0)\n",
        "        t_in = torch.cat([t, t], dim = 0)\n",
        "\n",
        "        eps_uncond, eps_cond = model(x_in, t_in, y_in).chunk(2, dim = 0)\n",
        "        eps_pred = eps_uncond + cfg_scale * (eps_cond - eps_uncond)\n",
        "\n",
        "\n",
        "        alpha_t = sched.alphas[t].view(num_imgs, 1, 1, 1)\n",
        "        beta_t = sched.betas[t].view(num_imgs, 1, 1, 1)\n",
        "        a_bar_t = sched.a_bar[t].view(num_imgs, 1, 1, 1)\n",
        "\n",
        "        mean = (1 / torch.sqrt(alpha_t)) * (x - ((beta_t / torch.sqrt(1 - a_bar_t)) * eps_pred))\n",
        "\n",
        "        if ti > 0:\n",
        "            if sigma_choice == \"beta_tilde\":\n",
        "                var = sched.post_var[t].view(num_imgs, 1, 1, 1).clamp_min(1e-20)\n",
        "            else:\n",
        "                var = beta_t\n",
        "\n",
        "            x = mean + (torch.sqrt(var) * torch.randn_like(x))\n",
        "        else:\n",
        "            x = mean\n",
        "\n",
        "    return x.clamp(-1, 1)"
      ],
      "metadata": {
        "id": "dtZK5Za1LZwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_for_inception(imgs : torch.tensor):\n",
        "    # imgs : [B, c, h, w]\n",
        "    if imgs.shape[1] == 1:\n",
        "        imgs = imgs.repeat(1, 3, 1, 1) # As inception network takes in imgs with 3 channels.\n",
        "\n",
        "    imgs = (imgs + 1.0) / 2.0 # [-1, 1] -> [0, 1]\n",
        "    imgs = F.interpolate(imgs, size = (299, 299), align_corners = False, mode = \"bilinear\")\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406], device = imgs.device).view(1, 3, 1, 1)\n",
        "    std  = torch.tensor([0.229, 0.224, 0.225], device = imgs.device).view(1, 3, 1, 1)\n",
        "\n",
        "    imgs = (imgs - mean) / std\n",
        "    return imgs"
      ],
      "metadata": {
        "id": "XOguJnL1Vwkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_inception():\n",
        "    model = inception_v3(weights = Inception_V3_Weights.IMAGENET1K_V1) # During inference, returns only last output, not aux outputs\n",
        "    model.eval().to(device)\n",
        "    return model"
      ],
      "metadata": {
        "id": "G8pglurCcLM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inception_outputs(inception : nn.Module, imgs : torch.Tensor, device = device):\n",
        "    imgs = preprocess_for_inception(imgs.to(device))\n",
        "    collected = {}\n",
        "\n",
        "    def hook_fn(m, i, o):\n",
        "        collected[\"feats\"] = torch.flatten(o, 1)\n",
        "\n",
        "    h = inception.avgpool.register_forward_hook(hook_fn)\n",
        "    logits = inception(imgs)\n",
        "    h.remove()\n",
        "\n",
        "    return collected[\"feats\"], logits"
      ],
      "metadata": {
        "id": "iZ0ZVVB2dEU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def inception_score_from_logits(logits : torch.Tensor, splits : int = 10):\n",
        "    # logits : [B, 1000]\n",
        "    probs = F.softmax(logits, dim = -1)\n",
        "    split_size = logits.shape[0] // splits\n",
        "    scores = []\n",
        "\n",
        "    for i in range(splits):\n",
        "        part = probs[i * split_size : (i + 1) * split_size]\n",
        "        p_y = part.mean(dim = 0, keepdim = True) # [1, 1000]\n",
        "        kl = (part * (torch.log(part + 1e-12) - torch.log(p_y + 1e-12))).sum(dim = 1) # [B, ]\n",
        "        scores.append(torch.exp(kl.mean()))\n",
        "\n",
        "    return torch.stack(scores).mean().item()"
      ],
      "metadata": {
        "id": "zIMBYnuFfKP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _cov(x : torch.Tensor):\n",
        "    # x : [B, D]\n",
        "    mu = x.mean(dim = 0, keepdim = True)\n",
        "    x_ = x - mu\n",
        "    return torch.matmul(x_.transpose(0, 1), x_) / (x.shape[0] - 1)"
      ],
      "metadata": {
        "id": "Eu7ytL-VhvcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_and_cov(feats):\n",
        "    mean = feats.mean(dim = 0)\n",
        "    cov = _cov(feats)\n",
        "    return mean, cov"
      ],
      "metadata": {
        "id": "ccbbJqfvk4ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sqrt_trace_cov(sigma_1 : torch.Tensor, sigma_2 : torch.tensor):\n",
        "    # sigma_1 : [D, D], sigma_2 : [D, D]\n",
        "    # sqrt(sigma_1) * sigma_2 * sqrt(sigma_1)\n",
        "\n",
        "    S1, U1 = torch.linalg.eigh(sigma_1) # S : [D, ], U : [D, D]\n",
        "    S1 =  S1.clamp_min(1e-12).unsqueeze(0) # [1, D]\n",
        "    sqrt_sigma_1 = torch.matmul(U1 * torch.sqrt(S1), U1.T)\n",
        "\n",
        "    A = sqrt_sigma_1 @ sigma_2 @ sqrt_sigma_1\n",
        "\n",
        "    Sa, Ua = torch.linalg.eigh((A + A.T) / 2)\n",
        "    Sa = Sa.clamp_min(1e-12).unsqueeze(0)\n",
        "    return torch.sqrt(Sa).sum()"
      ],
      "metadata": {
        "id": "QMt3ta8klGHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fid_from_stats(mu_1, sigma_1, mu_2, sigma_2):\n",
        "    diff = pow(mu_1 - mu_2, 2).sum()\n",
        "    tr = torch.trace(sigma_1 + sigma_2) - 2 * sqrt_trace_cov(sigma_1, sigma_2)\n",
        "    return (diff + tr).item()"
      ],
      "metadata": {
        "id": "haJ2gNlaz94H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def get_real_stats(dataloader, inception, device = device, max_images = 5000):\n",
        "    feats_list, logits_list = [], []\n",
        "    cnt = 0\n",
        "\n",
        "    for x, _ in dataloader:\n",
        "        x = x.to(device)\n",
        "        feats, logits = inception_outputs(inception, x, device)\n",
        "        feats_list.append(feats)\n",
        "        logits_list.append(logits)\n",
        "\n",
        "        cnt += len(x)\n",
        "\n",
        "        if cnt >= max_images:\n",
        "            break\n",
        "\n",
        "    feats = torch.cat(feats_list, dim = 0)[: max_images]\n",
        "    logits = torch.cat(logits_list, dim = 0)[: max_images]\n",
        "    mu, sigma = mean_and_cov(feats)\n",
        "    return mu, sigma, logits"
      ],
      "metadata": {
        "id": "ERXe7U_d1KKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def get_fake_stats(unet, inception, device = device, num_imgs = 5000, cfg_scale = 3.0, steps = None, num_classes = 10):\n",
        "    B = 512 # generation batch size\n",
        "    feats_list, logits_list = [], []\n",
        "    cnt = 0\n",
        "    null_id = num_classes\n",
        "    per_class = math.ceil(num_imgs / num_classes)\n",
        "\n",
        "    pbar = tqdm(total = num_imgs, desc = \"Fake_Stats\")\n",
        "\n",
        "    while cnt < num_imgs:\n",
        "        labels = []\n",
        "        for c in range(num_classes):\n",
        "            labels.extend([c] * min(per_class, B // num_classes))\n",
        "        labels = labels[: B]\n",
        "\n",
        "        y = torch.tensor(labels, dtype = torch.int64, device = device)\n",
        "        imgs = sample_grid(unet, y, y.shape[0], steps = steps, cfg_scale = cfg_scale, num_classes = num_classes, device = device)\n",
        "\n",
        "        feats, logits = inception_outputs(inception, imgs, device)\n",
        "        feats_list.append(feats)\n",
        "        logits_list.append(logits)\n",
        "        cnt += y.shape[0]\n",
        "\n",
        "        pbar.update(y.shape[0])\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "\n",
        "    feats = torch.cat(feats_list, dim = 0)[: num_imgs]\n",
        "    logits = torch.cat(logits_list, dim = 0)[: num_imgs]\n",
        "\n",
        "    mu, sigma = mean_and_cov(feats)\n",
        "    return mu, sigma, logits"
      ],
      "metadata": {
        "id": "oUGRPRRh4wq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def compute_IS_FID(unet, train_loader, device = device, num_fakes = 5000, steps = None, cfg_scale = 3.0, num_classes = 10, cache_real_stats = True, real_stats_path = None):\n",
        "    inception = load_inception()\n",
        "\n",
        "    if real_stats_path is None:\n",
        "        real_stats_path = \"samples/real_stats.pt\" # Keep it in \"samples\" folder\n",
        "\n",
        "    if cache_real_stats and os.path.isfile(real_stats_path):\n",
        "        ckpt = torch.load(real_stats_path, map_location = device)\n",
        "        mu_r, sigma_r, logits_r = ckpt[\"mu\"], ckpt[\"sigma\"], ckpt[\"logits\"]\n",
        "    else:\n",
        "        mu_r, sigma_r, logits_r = get_real_stats(train_loader, inception, device)\n",
        "        os.makedirs(\"samples\", exist_ok = True)\n",
        "        torch.save({\"mu\" : mu_r, \"sigma\" : sigma_r, \"logits\" : logits_r}, real_stats_path)\n",
        "\n",
        "    mu_f, sigma_f, logits_f = get_fake_stats(unet, inception, device, num_fakes, cfg_scale, steps, num_classes)\n",
        "    IS = inception_score_from_logits(logits_f)\n",
        "    FID = fid_from_stats(mu_r, sigma_r, mu_f, sigma_f)\n",
        "    return IS, FID"
      ],
      "metadata": {
        "id": "-dUYXUJDA0vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet = UNET().to(device)\n",
        "print(f\"{count_params(unet):,} params\")\n",
        "ema = EMA(unet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ3_rymBXBFl",
        "outputId": "4c5b2bc4-b56c-4bdd-9a14-91d35f875c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1,916,865 params\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epochs = 20, lr = 2e-4, checkpoint = \"mnist_ddpm.pt\", weighted = False, p_uncond = 0.1, num_classes = 10):\n",
        "    optim = torch.optim.Adam(model.parameters(), lr = lr,  weight_decay = 1e-4) # L2 Reg.\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled = (device == \"cuda\"))\n",
        "\n",
        "    model.train()\n",
        "    itr = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"Epoch : {epoch}\")\n",
        "        for x_0, y in tqdm(train_loader, total = len(train_loader)):\n",
        "            x_0 = x_0.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            null_id = num_classes\n",
        "            drop_mask = (torch.rand_like(y.float()) < p_uncond)\n",
        "            y_train = y.clone()\n",
        "            y_train[drop_mask] = null_id\n",
        "\n",
        "\n",
        "            t = torch.randint(0, sched.T, size = (x_0.shape[0], ), dtype = torch.int64, device = device)\n",
        "\n",
        "            with torch.cuda.amp.autocast(enabled = (device == \"cuda\")):\n",
        "                loss = loss_eps(model, x_0, t, y_train, weighted)\n",
        "\n",
        "\n",
        "            optim.zero_grad(set_to_none = True)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optim)\n",
        "            scaler.update()\n",
        "            ema.update()\n",
        "\n",
        "\n",
        "            if itr % 200 == 0:\n",
        "                print(f\"itr : {itr:06d}, Loss : {loss.item():.4f}\")\n",
        "\n",
        "            itr += 1\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_sample = torch.arange(0, 10).repeat_interleave((16 // 10) + 1)[: 16]\n",
        "\n",
        "            ema.store()\n",
        "            ema.copy_to()\n",
        "            imgs = sample_grid(model, y_sample, num_imgs = len(y_sample))\n",
        "            ema.restore()\n",
        "\n",
        "            grid = vutils.make_grid((imgs + 1) / 2, nrow = 4)\n",
        "            os.makedirs(\"samples\", exist_ok = True)\n",
        "            vutils.save_image(grid, f\"samples/{epoch:03d}.png\")\n",
        "\n",
        "            if epoch % 10 == 0 or epoch == 1:\n",
        "                # Takes 5 min, as generated fake images for fake stats.\n",
        "                IS, FID = compute_IS_FID(unet, train_loader)\n",
        "                print(f\"\\nEpoch : {epoch:03d}, FID : {FID:.2f}, IS : {IS:.2f}\\n\")\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), checkpoint)"
      ],
      "metadata": {
        "id": "iuz9NqJpJVvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(unet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1lrm0o6VMt8",
        "outputId": "abe6ca13-42e1-4b79-c8b8-df82306a023a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-816167186.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled = (device == \"cuda\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]/tmp/ipython-input-816167186.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled = (device == \"cuda\")):\n",
            "  1%|          | 4/469 [00:31<45:56,  5.93s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 000000, Loss : 0.9882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 205/469 [00:39<00:10, 24.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 000200, Loss : 0.0623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 403/469 [00:47<00:02, 24.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 000400, Loss : 0.0328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [01:17<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104M/104M [00:00<00:00, 194MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2048]) torch.Size([2048, 2048]) torch.Size([5000, 1000])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fake_Stats: 5100it [05:22, 15.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : 1, FID : 79.78657531738281, IS : 2.708458423614502\n",
            "\n",
            "Epoch : 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 136/469 [00:05<00:15, 22.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 000600, Loss : 0.0297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 334/469 [00:14<00:05, 24.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 000800, Loss : 0.0295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:19<00:00, 23.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 66/469 [00:03<00:18, 22.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 001000, Loss : 0.0317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 267/469 [00:12<00:09, 22.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 001200, Loss : 0.0278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 465/469 [00:21<00:00, 22.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 001400, Loss : 0.0263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:21<00:00, 21.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 196/469 [00:08<00:11, 24.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 001600, Loss : 0.0240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 397/469 [00:16<00:02, 24.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 001800, Loss : 0.0225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:19<00:00, 24.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 127/469 [00:05<00:14, 22.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 002000, Loss : 0.0221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 328/469 [00:14<00:06, 21.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 002200, Loss : 0.0271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 58/469 [00:02<00:18, 21.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 002400, Loss : 0.0283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 259/469 [00:11<00:08, 24.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 002600, Loss : 0.0227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 460/469 [00:19<00:00, 24.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 002800, Loss : 0.0276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 190/469 [00:08<00:13, 20.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 003000, Loss : 0.0242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 390/469 [00:16<00:03, 25.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 003200, Loss : 0.0352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 121/469 [00:05<00:14, 24.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 003400, Loss : 0.0245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▊   | 322/469 [00:13<00:05, 24.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 003600, Loss : 0.0263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:19<00:00, 23.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 52/469 [00:02<00:16, 24.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 003800, Loss : 0.0269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 253/469 [00:10<00:09, 22.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 004000, Loss : 0.0228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 451/469 [00:19<00:00, 21.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 004200, Loss : 0.0223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 184/469 [00:07<00:12, 22.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 004400, Loss : 0.0243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 382/469 [00:16<00:03, 24.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 004600, Loss : 0.0245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.14it/s]\n",
            "Fake_Stats: 5100it [05:18, 16.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : 10, FID : 15.860332489013672, IS : 2.275853395462036\n",
            "\n",
            "Epoch : 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 115/469 [00:04<00:14, 24.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 004800, Loss : 0.0230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 313/469 [00:13<00:07, 21.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 005000, Loss : 0.0241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:21<00:00, 22.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 46/469 [00:01<00:17, 24.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 005200, Loss : 0.0219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 244/469 [00:10<00:09, 24.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 005400, Loss : 0.0208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 445/469 [00:19<00:01, 21.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 005600, Loss : 0.0231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 178/469 [00:07<00:11, 24.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 005800, Loss : 0.0228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 376/469 [00:15<00:03, 25.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 006000, Loss : 0.0190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:19<00:00, 24.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 106/469 [00:05<00:17, 21.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 006200, Loss : 0.0240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 307/469 [00:13<00:06, 23.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 006400, Loss : 0.0260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▊         | 40/469 [00:01<00:17, 24.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 006600, Loss : 0.0231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 238/469 [00:09<00:10, 22.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 006800, Loss : 0.0233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▎| 439/469 [00:18<00:01, 25.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 007000, Loss : 0.0317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:19<00:00, 23.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 169/469 [00:07<00:12, 24.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 007200, Loss : 0.0193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 370/469 [00:15<00:03, 24.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 007400, Loss : 0.0239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:19<00:00, 23.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██▏       | 100/469 [00:04<00:16, 22.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 007600, Loss : 0.0243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 301/469 [00:13<00:07, 23.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 007800, Loss : 0.0197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 31/469 [00:01<00:19, 22.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 008000, Loss : 0.0255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 232/469 [00:10<00:11, 20.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 008200, Loss : 0.0258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 430/469 [00:18<00:01, 23.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 008400, Loss : 0.0214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:20<00:00, 23.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 163/469 [00:07<00:13, 23.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 008600, Loss : 0.0254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 364/469 [00:15<00:04, 24.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 008800, Loss : 0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:19<00:00, 23.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 94/469 [00:03<00:15, 24.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 009000, Loss : 0.0216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 295/469 [00:12<00:07, 24.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "itr : 009200, Loss : 0.0265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 469/469 [00:19<00:00, 23.75it/s]\n",
            "Fake_Stats: 5100it [05:18, 16.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch : 20, FID : 21.35757064819336, IS : 2.4000580310821533\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dig(unet : nn.Module, dig = None, num_imgs = 16, steps = 1000, ckpt = None, sigma_choice = \"beta_tilde\", cfg_scale = 3.0, num_classes = 10, return_imgs = False):\n",
        "    if ckpt is not None:\n",
        "        unet.load_state_dict(torch.load(ckpt), map_location = device)\n",
        "\n",
        "    if dig is None:\n",
        "        dig = num_classes # null_id\n",
        "\n",
        "    y_label = torch.full((num_imgs, ), int(dig), device = device, dtype = torch.int64)\n",
        "    imgs = sample_grid(unet, y_label, num_imgs, sigma_choice = sigma_choice, steps = steps, cfg_scale = cfg_scale)\n",
        "    os.makedirs(\"samples\", exist_ok = True)\n",
        "    save_path = f\"samples/sample_digit_{dig}_steps_{steps}_cfg_scale_{cfg_scale}.png\"\n",
        "    grid = vutils.make_grid((imgs + 1) / 2, nrow = 4)\n",
        "    vutils.save_image(grid, save_path)\n",
        "    print(f\"Saved at : {save_path}\")\n",
        "\n",
        "    if return_imgs:\n",
        "        return imgs"
      ],
      "metadata": {
        "id": "nQmiYJlUNm5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_dig(unet, dig = 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnGl_p6Lbino",
        "outputId": "1321881a-97a7-4711-9a0b-35430cef650e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved at : samples/sample_digit_6_steps_1000_cfg_scale_3.0.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = generate_dig(unet, return_imgs = True)"
      ],
      "metadata": {
        "id": "Ccl0xlH5kEE2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7f5d77-e389-4dc5-d53b-74a1cf842b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved at : samples/sample_digit_10_steps_1000_cfg_scale_3.0.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zM_tChClPQHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8U12k7_Bex1I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}